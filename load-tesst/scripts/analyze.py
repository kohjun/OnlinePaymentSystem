#!/usr/bin/env python3
"""
JMeter ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
Payment Service ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ìƒì„¸ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥
import sys
from pathlib import Path
from datetime import datetime

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class JMeterAnalyzer:
    """JMeter ê²°ê³¼ ë¶„ì„ê¸°"""

    def __init__(self, jtl_path):
        self.jtl_path = Path(jtl_path)
        self.df = None
        self.output_dir = self.jtl_path.parent

    def load_data(self):
        """JTL íŒŒì¼ ë¡œë“œ"""
        print(f"\nğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {self.jtl_path}")

        try:
            self.df = pd.read_csv(self.jtl_path)
            print(f"âœ… {len(self.df)} ê°œì˜ ìš”ì²­ ë¡œë“œ ì™„ë£Œ")

            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
            self.df['timeStamp'] = pd.to_datetime(self.df['timeStamp'], unit='ms')

            return True
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def print_summary(self):
        """ê¸°ë³¸ í†µê³„ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“Š ì‘ë‹µ ì‹œê°„ í†µê³„ (Response Time Statistics)")
        print("="*70)

        stats = self.df['elapsed'].describe()
        print(f"ì´ ìš”ì²­ ìˆ˜:        {len(self.df):,}")
        print(f"í‰ê·  (Mean):       {stats['mean']:.2f} ms")
        print(f"ì¤‘ì•™ê°’ (Median):    {self.df['elapsed'].median():.2f} ms")
        print(f"ìµœì†Œê°’ (Min):      {stats['min']:.2f} ms")
        print(f"ìµœëŒ€ê°’ (Max):      {stats['max']:.2f} ms")
        print(f"í‘œì¤€í¸ì°¨ (Std):    {stats['std']:.2f} ms")
        print(f"\në°±ë¶„ìœ„ìˆ˜ (Percentiles):")
        print(f"  P50 (Median):    {self.df['elapsed'].quantile(0.50):.2f} ms")
        print(f"  P90:             {self.df['elapsed'].quantile(0.90):.2f} ms")
        print(f"  P95:             {self.df['elapsed'].quantile(0.95):.2f} ms")
        print(f"  P99:             {self.df['elapsed'].quantile(0.99):.2f} ms")

    def analyze_tps(self):
        """TPS ë¶„ì„"""
        print("\n" + "="*70)
        print("âš¡ TPS (Transactions Per Second)")
        print("="*70)

        tps = self.df.set_index('timeStamp').resample('1S').size()

        print(f"í‰ê·  TPS:          {tps.mean():.2f}")
        print(f"ìµœëŒ€ TPS:          {tps.max():.2f}")
        print(f"ìµœì†Œ TPS:          {tps.min():.2f}")
        print(f"ì¤‘ì•™ê°’ TPS:        {tps.median():.2f}")

        return tps

    def analyze_success_rate(self):
        """ì„±ê³µë¥  ë¶„ì„"""
        print("\n" + "="*70)
        print("âœ… ì„±ê³µë¥  (Success Rate)")
        print("="*70)

        total = len(self.df)
        success = self.df['success'].sum()
        failed = total - success
        success_rate = (success / total) * 100

        print(f"ì „ì²´ ìš”ì²­:         {total:,}")
        print(f"ì„±ê³µ:              {success:,}")
        print(f"ì‹¤íŒ¨:              {failed:,}")
        print(f"ì„±ê³µë¥ :            {success_rate:.2f}%")

        if failed > 0:
            print(f"\nâš ï¸  ì‹¤íŒ¨í•œ ìš”ì²­ì´ ìˆìŠµë‹ˆë‹¤!")
            error_codes = self.df[self.df['success'] == False]['responseCode'].value_counts()
            print("\nì—ëŸ¬ ì½”ë“œ ë¶„í¬:")
            for code, count in error_codes.items():
                print(f"  {code}: {count}íšŒ")

    def analyze_by_endpoint(self):
        """ì—”ë“œí¬ì¸íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„"""
        print("\n" + "="*70)
        print("ğŸ¯ ì—”ë“œí¬ì¸íŠ¸ë³„ ì„±ëŠ¥ (Performance by Endpoint)")
        print("="*70)

        grouped = self.df.groupby('label').agg({
            'elapsed': ['count', 'mean', 'median', 'min', 'max',
                       lambda x: x.quantile(0.95)],
            'success': 'sum'
        }).round(2)

        # ì»¬ëŸ¼ëª… ì •ë¦¬
        grouped.columns = ['Count', 'Mean(ms)', 'Median(ms)', 'Min(ms)',
                          'Max(ms)', 'P95(ms)', 'Success']
        grouped['Success Rate (%)'] = (grouped['Success'] / grouped['Count'] * 100).round(2)

        print(grouped.to_string())

    def detect_bottlenecks(self):
        """ë³‘ëª© êµ¬ê°„ íƒì§€"""
        print("\n" + "="*70)
        print("ğŸ”¥ ë³‘ëª© êµ¬ê°„ íƒì§€ (Bottleneck Detection)")
        print("="*70)

        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì‘ë‹µ ì‹œê°„
        response_time_series = self.df.set_index('timeStamp')['elapsed'].resample('5S').mean()

        # í‰ê· ì˜ 2ë°° ì´ìƒì¸ êµ¬ê°„ì„ ë³‘ëª©ìœ¼ë¡œ ê°„ì£¼
        threshold = response_time_series.mean() * 2
        bottlenecks = response_time_series[response_time_series > threshold]

        if len(bottlenecks) > 0:
            print(f"âš ï¸  {len(bottlenecks)}ê°œì˜ ë³‘ëª© êµ¬ê°„ ë°œê²¬!")
            print(f"ì„ê³„ê°’ (í‰ê· ì˜ 2ë°°): {threshold:.2f} ms")
            print(f"\në³‘ëª© êµ¬ê°„ (ìƒìœ„ 10ê°œ):")
            for timestamp, response_time in bottlenecks.nlargest(10).items():
                print(f"  {timestamp.strftime('%Y-%m-%d %H:%M:%S')}: {response_time:.2f} ms")
        else:
            print("âœ… ë³‘ëª© êµ¬ê°„ ì—†ìŒ - ì•ˆì •ì ì¸ ì„±ëŠ¥")

        return response_time_series, threshold

    def analyze_latency_distribution(self):
        """ë ˆì´í„´ì‹œ ë¶„í¬ ë¶„ì„"""
        print("\n" + "="*70)
        print("ğŸ“ˆ ë ˆì´í„´ì‹œ ë¶„í¬ (Latency Distribution)")
        print("="*70)

        bins = [0, 50, 100, 200, 500, 1000, 2000, float('inf')]
        labels = ['0-50ms', '50-100ms', '100-200ms', '200-500ms',
                 '500-1000ms', '1-2s', '>2s']

        self.df['latency_bin'] = pd.cut(self.df['elapsed'], bins=bins, labels=labels)
        distribution = self.df['latency_bin'].value_counts().sort_index()

        print("\nì‘ë‹µ ì‹œê°„ ë¶„í¬:")
        for label, count in distribution.items():
            percentage = (count / len(self.df)) * 100
            bar = 'â–ˆ' * int(percentage / 2)
            print(f"  {label:12s}: {count:6,} ({percentage:5.1f}%) {bar}")

    def create_graphs(self, tps, response_time_series, threshold):
        """ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„±"""
        print("\n" + "="*70)
        print("ğŸ“Š ê·¸ë˜í”„ ìƒì„± ì¤‘...")
        print("="*70)

        fig, axes = plt.subplots(4, 1, figsize=(16, 18))
        fig.suptitle('Payment Service Performance Analysis', fontsize=16, fontweight='bold')

        # 1. TPS ê·¸ë˜í”„
        axes[0].plot(tps.index, tps.values, linewidth=2, color='#2196F3')
        axes[0].axhline(y=tps.mean(), color='red', linestyle='--',
                       label=f'Average: {tps.mean():.2f} TPS', linewidth=2)
        axes[0].set_title('Transactions Per Second (TPS)', fontsize=14, fontweight='bold')
        axes[0].set_ylabel('TPS', fontsize=12)
        axes[0].grid(True, alpha=0.3)
        axes[0].legend(fontsize=10)
        axes[0].set_xlabel('Time', fontsize=12)

        # 2. ì‘ë‹µ ì‹œê°„ ì¶”ì´
        axes[1].plot(response_time_series.index, response_time_series.values,
                    linewidth=2, color='#4CAF50')
        axes[1].axhline(y=response_time_series.mean(), color='red', linestyle='--',
                       label=f'Average: {response_time_series.mean():.2f} ms', linewidth=2)
        if threshold:
            axes[1].axhline(y=threshold, color='orange', linestyle='--',
                           label=f'Threshold (2x avg): {threshold:.2f} ms', linewidth=2)
        axes[1].set_title('Average Response Time', fontsize=14, fontweight='bold')
        axes[1].set_ylabel('Response Time (ms)', fontsize=12)
        axes[1].grid(True, alpha=0.3)
        axes[1].legend(fontsize=10)
        axes[1].set_xlabel('Time', fontsize=12)

        # 3. ì—ëŸ¬ìœ¨
        error_rate = self.df.set_index('timeStamp')['success'].resample('5S').apply(
            lambda x: (1 - x.mean()) * 100 if len(x) > 0 else 0
        )
        axes[2].plot(error_rate.index, error_rate.values, linewidth=2, color='#F44336')
        axes[2].axhline(y=error_rate.mean(), color='orange', linestyle='--',
                       label=f'Average: {error_rate.mean():.2f}%', linewidth=2)
        axes[2].set_title('Error Rate (%)', fontsize=14, fontweight='bold')
        axes[2].set_ylabel('Error Rate (%)', fontsize=12)
        axes[2].grid(True, alpha=0.3)
        axes[2].legend(fontsize=10)
        axes[2].set_xlabel('Time', fontsize=12)
        axes[2].set_ylim(bottom=0)

        # 4. ì‘ë‹µ ì‹œê°„ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)
        axes[3].hist(self.df['elapsed'], bins=50, edgecolor='black',
                    alpha=0.7, color='#9C27B0')
        axes[3].axvline(x=self.df['elapsed'].mean(), color='red', linestyle='--',
                       label=f'Mean: {self.df["elapsed"].mean():.2f} ms', linewidth=2)
        axes[3].axvline(x=self.df['elapsed'].median(), color='green', linestyle='--',
                       label=f'Median: {self.df["elapsed"].median():.2f} ms', linewidth=2)
        axes[3].axvline(x=self.df['elapsed'].quantile(0.95), color='orange', linestyle='--',
                       label=f'P95: {self.df["elapsed"].quantile(0.95):.2f} ms', linewidth=2)
        axes[3].set_title('Response Time Distribution', fontsize=14, fontweight='bold')
        axes[3].set_xlabel('Response Time (ms)', fontsize=12)
        axes[3].set_ylabel('Frequency', fontsize=12)
        axes[3].grid(True, alpha=0.3, axis='y')
        axes[3].legend(fontsize=10)

        plt.tight_layout()

        # ì €ì¥
        output_path = self.output_dir / 'performance_analysis.png'
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"âœ… ê·¸ë˜í”„ ì €ì¥: {output_path}")
        plt.close()

    def generate_report(self):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        report_path = self.output_dir / 'analysis_report.txt'

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("Payment Service Performance Test - Analysis Report\n")
            f.write("="*70 + "\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ë°ì´í„° íŒŒì¼: {self.jtl_path.name}\n")
            f.write(f"ì´ ìš”ì²­ ìˆ˜: {len(self.df):,}\n")
            f.write("\n")

            # ì£¼ìš” ì§€í‘œ
            f.write("ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ:\n")
            f.write(f"  í‰ê·  ì‘ë‹µì‹œê°„: {self.df['elapsed'].mean():.2f} ms\n")
            f.write(f"  P95 ì‘ë‹µì‹œê°„: {self.df['elapsed'].quantile(0.95):.2f} ms\n")
            f.write(f"  P99 ì‘ë‹µì‹œê°„: {self.df['elapsed'].quantile(0.99):.2f} ms\n")

            tps = self.df.set_index('timeStamp').resample('1S').size()
            f.write(f"  í‰ê·  TPS: {tps.mean():.2f}\n")
            f.write(f"  ìµœëŒ€ TPS: {tps.max():.2f}\n")

            success_rate = (self.df['success'].sum() / len(self.df)) * 100
            f.write(f"  ì„±ê³µë¥ : {success_rate:.2f}%\n")

        print(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        if not self.load_data():
            return False

        self.print_summary()
        tps = self.analyze_tps()
        self.analyze_success_rate()
        self.analyze_by_endpoint()
        response_time_series, threshold = self.detect_bottlenecks()
        self.analyze_latency_distribution()
        self.create_graphs(tps, response_time_series, threshold)
        self.generate_report()

        print("\n" + "="*70)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print("="*70)
        print(f"\nìƒì„±ëœ íŒŒì¼:")
        print(f"  ğŸ“Š ê·¸ë˜í”„: {self.output_dir}/performance_analysis.png")
        print(f"  ğŸ“„ ë¦¬í¬íŠ¸: {self.output_dir}/analysis_report.txt")
        print()

        return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python3 analyze.py <jtl_file_path>")
        print("\nì˜ˆì‹œ:")
        print("  python3 load-test/scripts/analyze.py load-test/results/20240315_120000/results.jtl")
        sys.exit(1)

    jtl_file = sys.argv[1]

    if not Path(jtl_file).exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {jtl_file}")
        sys.exit(1)

    # ë¶„ì„ ì‹¤í–‰
    analyzer = JMeterAnalyzer(jtl_file)
    success = analyzer.run_analysis()

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
